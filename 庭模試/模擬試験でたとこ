QUESTION 13 ★
この質問については、Mountkirk Games のケーススタディを参照してください。
Mountkirk Gamesは、現在の分析および統計レポートモデルから、Google Cloud Platform 上の技術的要件を満たすモデルに移行したいと考えています。
移行計画に含めるべき2つのステップはどれでしょうか？(回答は2つ)

A. 現在のバッチ ETL コードをCloud Cloud Dataflow に移行した場合の影響を評価します。
B. Google BigQuery のパフォーマンスを向上させるために、データを非正規化するスキーマ移行計画を作成します。
C. 単一のMySQL データベースからMySQL クラスタに移動する方法を示すアーキテクチャ図を作成します。
D. 前のゲームから10 TBの分析データをGoogle Cloud SQL インスタンスにロードし、データセット全体に対してテストクエリを実行して、正常に完了したことを確認します。
E. Google Cloud Armor を統合して、Google Cloud Storage にアップロードされた分析ファイル内のSQL インジェクション攻撃の可能性を防ぎます。

A,E → A,B
データを非正規化するでおかしいかなと思ったけど、勘違いやった。非正規化することで構造が単純化するので、DBのパフォーマンスは上がる。
よくわからんCloudArmorを選択したのがよくなかった。そもそもビッグデータを整形して分析するのが目的やから、CloudStorageのSQLデータを守るとか関係ないし、そもそもCloudArmorはLBを守ってるからStorageは守らない。


QUESTION 14 ★
この質問については、Mountkirk Games のケーススタディを参照してください。
会社のMountkirk Gamesのコンピューティングワークロードの技術アーキテクチャを分析および定義する必要があります。
Mountkirk Gamesのビジネス要件と技術的要件を考慮して、何をすべきですか？

A. ネットワーク ロードバランサを作成します。 Google Compute Engine プリエンプティブル インスタンスを使用します。
B. ネットワーク ロードバランサを作成します。Google Compute Engine インスタンスを使用します。
C. マネージド インスタンス グループ（MIG）と自動スケーリングポリシーを使用してネットワーク ロードバランサを作成します。Googel Compute Engine プリエンプティブル インスタンスを使用します。
D. マネージド インスタンス グループ（MIG）と自動スケーリングポリシーを使用してネットワーク ロードバランサを作成します。 Google Compute Engine インスタンスを使用します。

D 正解
技術要件でオートスケーリングすることが求められてるから、LBを用意するだけはNG。
プリエンプティブルインスタンスは需要によって停止する可能性があるから本番登用は危険。


QUESTION 18 ★
この質問については、Mountkirk Games のケーススタディを参照してください。
時系列データベースサービスにゲームアクティビティを保存するためのMountkirk の技術的要件を満たすGoogle Cloud ストレージ プロダクトはどれでしょうか？

A. Google Cloud Bigtable
B. Google Cloud Spanner
C. Google BigQuery
D. Google Cloud Datastore

C → A
時系列データベース：IoT機器から収集されるログファイルとかは時系列データ。タイムスタンプが押してあって、キーとバリュー。
こういうのはBigtableで受ける。
まず、BigQueryがデータウェアハウスなので、データベースとして使うのは間違い。


QUESTION 19 ★
この質問については、Mountkirk Games のケーススタディを参照してください。
新しいゲームバックエンド プラットフォームのアーキテクチャを担当しています。
ゲームはREST API を介してバックエンドと通信します。
Google のベストプラクティスに従います。
バックエンドをどのように設計すべきか？

A. バックエンドのインスタンス テンプレートを作成します。 すべてのリージョンについて、複数ゾーンのマネージド インスタンス グループ（MIG）にデプロイします。 L4 ロードバランサ（TCP プロキシ負荷分散）を使用します。
B. バックエンドのインスタンス テンプレートを作成します。 リージョンごとに、単一ゾーンのマネージド インスタンス グループ（MIG）にデプロイします。 L4 ロードバランサ（TCP プロキシ負荷分散）を使用します。
C. バックエンドのインスタンス テンプレートを作成します。 すべてのリージョンについて、複数ゾーンのマネージド インスタンス グループ（MIG）にデプロイします。L7 ロードバランサ（HTTP(S) 負荷分散）を使用します。
D. バックエンドのインスタンス テンプレートを作成します。 リージョンごとに、単一ゾーンのマネージド インスタンス グループ（MIG）にデプロイします。 L7 ロードバランサ（HTTP(S) 負荷分散）を使用します。

C → A
考えたけどなんで間違いかわからん。REST APIやからURL叩いてる＝HTTP(S)やと思ったんやが、、、
内部LBやからL4でいいってことなんかね。


QUESTION 33 ★
この質問については、TerramEarth のケーススタディを参照してください。
TerramEarthのデータ ウェアハウスに、信頼性と拡張性に優れたGCP ソリューションを実装する必要があります。
TerramEarthのビジネス要件と技術的要件を考慮してください。
何をするべきでしょうか？

A. 既存のデータ ウェアハウスをGoogle BigQueryに置き換え、パーティション分割テーブルを使用します。
B. 既存のデータ ウェアハウスを96個のvCPUを持つGoogle Compute Engine インスタンスに置き換えます。
C. 既存のデータ ウェアハウスをGoogle BigQuery に置き換え、外部データソース（フェデレーション データソース）を使用します。
D. 既存のデータ ウェアハウスを96個のvCPUのGoogle Compute Engine インスタンスに置き換え、 32個のvCPUのGoogle Compute Engine プリエンプティブル インスタンスを追加します。

A 正解
外部データソース：
BigQuery外に保存されたデータソースの事。つまり、Bigtable,Storage,Drive,SQL
外部データソースを使う場合、いろんな制限があるから、あんまり使わんほうがええかもしれん。
パーティション分割テーブル：
タイムスタンプとか、整数範囲とかのパーティションに分割したテーブルを作ることで、データの照会、管理とかを簡単にできる。
クエリのパフォーマンス向上とコスト削減を実現できる。
96個のVM～～ってのはスケーリングに問題あるし、TerramEarthの技術要件にデータウェアハウスを何とかしたいって書いてるからBigQueryをあえて使わない理由はないはず。


QUESTION 34 ★
この質問については、TerramEarth のケーススタディを参照してください。
すべての入力データをGoogle BigQuery に書き込む新しいアーキテクチャが導入されました。
データが汚れていることに気付き、コストを管理しながら、毎日自動化されたデータ品質を確保したいと考えています。
何をするべきでしょうか？

A. Google Cloud Dataflow ストリーミング ジョブを設定し、取り込みプロセスでデータを受信します。 Google Cloud Dataflow パイプラインのデータをクリーンアップします。
B. Google BigQuery からデータを読み取り、クリーンアップするGoogle Cloud Functions を作成します。Google Compute EngineインスタンスからGoogle Cloud Functions をトリガーします。
C. Google BigQuery のデータにSQL文を作成し、ビューとして保存します。 ビューを毎日実行し、結果を新しいテーブルに保存します。
D. Google Cloud Dataprep を使用して、Google BigQuery テーブルをソースとして構成します。 データを消去するために毎日のジョブをスケジュールします。

A → D
完全にDataPrepを知らなかったから間違えた問題。
DataPrepは汚れたデータのクリーニングに使われるらしい。BigQueryをデータソースにして、Prepできれいにした後DataFlowに送るとかがユースケースに載ってた。
あとスケジュールもできるってのも概要に載ってる。
残念。次受けるときはほんまに全部ドキュメント網羅したうえで受けなあかんなと痛感した。


QUESTION 35 ★
この質問については、TerramEarth のケーススタディを参照してください。
TerramEarthの技術的要件を考慮した場合、Google Cloud Platform で予想外の車両のダウンタイムをどのように削減するべきですか?

A. Google BigQuery をデータ ウェアハウスとして使用します。 すべての車両をネットワークに接続し、Google Cloud Pub/Sub とGoogle Cloud Dataflow を使用してデータをGoogle BigQuery にストリーミングします。分析とレポートにGoogle データポータル（データスタジオ） を使用します。
B. Google BigQuery をデータ ウェアハウスとして使用します。すべての車両をネットワークに接続し、gcloud を使用してgzip ファイルをGoogle Cloud Multi-Regional Storage バケットにアップロードします。 分析とレポートにGoogle データポータルを使用します。
C. Google Cloud Dataproc Hive をデータ ウェアハウスとして使用します。gzip ファイルをGoogle Cloud Multi-Regional Storage バケットにアップロードします。gcloud を使用して、このデータをGoogle BigQuery にアップロードします。分析とレポートにGoogle データポータルを使用します。
D. Google Cloud Dataproc Hive をデータウェアハウスとして使用します。パーティション化されたHive テーブルにデータを直接ストリーミングします。Pig スクリプトを使用してデータを分析します。

A 正解
これはもろに理想的なユースケースを選ぶ問題。簡単。
StorageにアップするのはgcloudじゃなくてgsutilなのでBは×,DWHはBigQuery使わない理由がないからC,DもNG
Cで、gcloudでBigQueryにアップロードするってあるけどbqコマンドちゃうかな、、

QUESTION 36 ★
この質問については、TerramEarth のケーススタディを参照してください。
携帯電話ネットワークに接続されている20万台の車両のデータを取り込むための新しいアーキテクチャを設計するよう求められます。
Google のベストプラクティスに従ってください。
TerramEarthの技術的要件を考慮すると、データの取り込みにはどのコンポーネントを使用する必要がありますか。

A. SSL Ingress を使用したGoogle Kubernetes Engine。
B. 公開鍵 / 秘密鍵ペアを使用したGoogle Cloud IoT Core。
C. プロジェクト全体のSSH 認証鍵を備えたGoogle Compute Engine。
D. 特定のSSH 認証鍵を持つGoogle Compute Engine。

B 正解
IoTにはIoTコア使えばええやん。

QUESTION 38 ★
この質問については、Dress4Win のケーススタディを参照してください。Dress4Winでは、運用エンジニアが、データベースのバックアップ ファイルのコピーをリモートでアーカイブするための低コストのソリューションを作成しようとしています。
データベース ファイルは、現在のデータセンターに格納されている圧縮 tar ファイルです。
何をするべきでしょうか？

A. gsutil を使用してcron スクリプトを作成し、ファイルをColdline Storage バケットにコピーします。
B. gsutil を使用してcron スクリプトを作成し、ファイルをRegional Storage バケットにコピーします。
C. Google Cloud Storage Transfer Service ジョブを作成して、ファイルをColdline Storage バケットにコピーします。
D. Google Cloud Storage Transfer Service ジョブを作成して、ファイルをRegional Storage バケットにコピーします。

B → A
→低コストやからColdLine?この問題やってない気がする。どっちにしろ間違えた。慎重に選ぼう。NearとColdの使い分け、料金がかかるタイミングとか。


Explanation:
gsutil とGoogle Cloud Storage Transfer Serviceのどちらを使用するかを決定する際は、次のルールに従ってください。

オンプレミスのロケーションからデータを転送する場合は、gsutil を使用します。
別のクラウド ストレージ プロバイダからデータを転送する場合は、Google Cloud Storage Transfer Service を使用します。
それ以外の場合は、具体的な状況を勘案して両方のツールを評価してください。
このガイダンスをベースとして使用します。転送シナリオの詳細は、適切なツールを判断するときにも役立ちます。

Rerence:
– Storage Transfer Service の概要

QUESTION 52 ★
この質問については、Dress4Win のケーススタディを参照してください。Dress4WinのGoogle Cloud Storage に保存されたデータのセキュリティに責任があります。
既にGoogle グループのセットを作成し、適切なユーザーをそれらのグループに割り当てています。
Google ベストプラクティスに従って、ビジネス要件と技術的要件を満たすために最も単純な設計を実装する必要があります。
何をするべきでしょうか？

A. セキュリティ要件を実施するために、作成したGoogle グループにIAMのカスタムの役割を割り当てます。Google Cloud Storage にファイルを保存するときに、顧客が用意した暗号鍵でデータを暗号化します。
B. セキュリティ要件を実施するために、作成したGoogle グループにIAMのカスタムの役割を割り当てます。Google Cloud Storage にファイルを保存する前に、デフォルトのストレージ暗号化を有効します。
C. セキュリティ要件を実施するために、作成したGoogle グループに定義済みのIAMの役割を割り当てます。Google Cloud Storage にファイルを保存するときに、Google のデフォルトの暗号化を保存時に使用します。
D. セキュリティ要件を実施するために、作成したGoogle グループに定義済みのIAMの役割を割り当てます。Google Cloud Storage にファイルを保存する前に、デフォルトのGoogle Cloud KMS の暗号鍵が設定されていることを確認します。

A → C
技術要件に、迅速なリソースのプロビジョニングとビジネスの俊敏性とイノベーションのスピードの向上ってあるから、カスタムの役割をいちいち作るよりかは、事前定義されたIAMを使うってことか。
→ちゃうわ問題文にもっとも単純な設計を実装する必要があるって書いてある。
暗号化のほうは、クライアント側かサーバ側かで暗号化する場合と、ファイルの保存前後で暗号化するのかいろいろ違う。
クライアント側：データ送信”前”に暗号化される。デフォルトで暗号化される。送信後、サーバ側でも暗号化される。
サーバ側：データが送信された後に暗号化してから保存される。この時、顧客管理の暗号かぎが使える。デフォルトより強固。KMSも使える。
結局一番単純な実装は、事前定義されたIAM使って、デフォの暗号化使えばいいので正解はCやね。問題文嫁。


QUESTION 53 ★
この質問については、Dress4Win のケーススタディを参照してください。
ソリューションを移行する前に、オンプレミス アーキテクチャがビジネス要件を満たしていることを確認する必要があります。
オンプレミスのアーキテクチャをどのように変更する必要がありますか？

A. RabbitMQ をGoogle Cloud Pub / Subに置き換えます。
B. MySQL をGoogle Cloud SQL for MySQL でサポートされているv5.7にダウングレードします。
C. 事前定義されたGoogle Compute Engine マシンタイプに一致するようにコンピューティング リソースのサイズを変更します。
D. マイクロサービスをコンテナ化し、Google Kubernetes Engine でホストします。

A → C
”オンプレミスが”ビジネス要件を満たしてるかどうかを確認するから、クラウドサービスに置き換えるのはおかしいのかもしれない。
でもさすがにMySQLをダウングレードするのは再現性が下がりそう。
ｸｰﾊﾞﾈﾃｨｽを使うのは技術コスト高いし再現性も低いからよくない。
オンプレのリソースを移行後のComputeEngineに合わせるのは、再現性の高さに結びつくと思うからCが正解やとおもう。


QUESTION 69 ★
会社は、低リスクでパブリック クラウドを試してみたいと思っています。
約100 TBのログデータをパブリック クラウドにアーカイブし、そこで利用可能な分析機能をテストすると同時に、そのデータを長期の災害復旧バックアップとして保持したいと考えています。
どの手段を選択するべきでしょうか？（回答は2つ）

A.ログをGoogle BigQuery にロードします。
B.ログをGoogle Cloud SQL にロードします。
C.ログをGoogle Stackdriver にインポートします。
D.ログをGoogle Cloud Bigtable にインポートします。
E.ログファイルをGoogle Cloud Storage にアップロードします。

A,E 正解
これは模擬試験でやった気がする。
ビッグデータのアーカイブ、分析はDWHのBigQueryが最適で、長期バックアップにはStorageが最適。


QUESTION 71 ★
カスタマーサポートツールは、保持と分析のために、すべてのメールとチャットの会話をGoogle Cloud Bigtable に記録します。
個人を特定できる情報または支払いカード情報のデータを初期保存する前にサニタイズ（sanitize）するための推奨されるアプローチは何ですか？

A. SHA256 を使用してすべてのデータをハッシュします。
B. 楕円曲線暗号を使用してすべてのデータを暗号化します。
C. Google Cloud Data Loss Prevention API を使用してデータの識別を解除します。
D. 正規表現を使用して、電話番号、メールアドレス、クレジットカード番号を見つけて編集します。

C 正解
直前に1行のやつで見たから正解できた。

Reference:
– Cloud Data Loss Prevention を使用してデータをサニタイズする (opens in a new tab)”>PCI データ セキュリティ基準の遵守>Cloud Data Loss Prevention を使用してデータをサニタイズする


QUESTION 73 ★
Google Compute Engine インスタンスとオンプレミスのデータセンターの間にプライベート接続を作成します。
少なくとも20 Gbpsの接続が必要です。Google のベストプラクティスに従いまし
接続をどのように設定するべきでしょうか？？

A. VPCを作成し、Dedicated Interconnect を使用してオンプレミスのデータセンターに接続します。
B. VPCを作成し、単一のGoogle Cloud VPN を使ってオンプレミスのデータセンターに接続します。
C. Google Cloud Content Delivery Network（Google Cloud CDN）を作り、Dedicated Interconnect を使ってオンプレミスのデータセンターに接続します。
D. Google Cloud CDN を作り、単一のGoogle Cloud VPN でオンプレミスのデータセンターに接続します。

A 正解
20Gbpsの帯域が必要ならDedicatedInterconnectを使うしかない。


QUESTION 74 ★
スタートアップが、GCP をを試験的に利用するためのビジネスプロセスを分析と定義していますが、製品に対する消費者の需要がどうなるかはまだわかりません。
マネージャーは、GCP サービスコストを最小限に抑え、Google のベストプラクティスに従うことを望んでいます。
何をするべきでしょうか？

A. 無料枠と継続利用割引を利用し、サービスコスト管理のためのスタッフを配置します。
B. 無料枠と継続利用割引を利用し、サービスコスト管理についてのトレーニングをチームに受けさせます。
C. 無料枠と確定利用割引を利用し、サービスコスト管理のためのスタッフを配置します。
D. 無料枠と確定利用割引を利用し、サービスコスト管理についてのトレーニングをチームに受けさせます。

A → B
”サービスコストを最小限に抑え”やからトレーニングのほうなんかな？
どっちも高そうやけど。。。　まぁこれはむずいしゃーない。


QUESTION 80 ★
Google Cloud Platafrom（GCP）でMicrosoft SQL Server をセットアップする必要があります。
管理では、GCP リージョン内のいずれかのゾーンでデータセンターが停止した場合にダウンタイムがないことが必要です。
何をするべきでしょうか？

A. 高可用性を有効にしてGoogle Cloud SQL インスタンスを構成します。
B. 地域インスタンス構成でGoogle Cloud Spanner インスタンスを構成します。
C. Windows Server のフェールオーバー クラスタリングを使用したAlways On の可用性グループを使用して、Google Compute Engine でSQL Server をセットアップします。 ノードを異なるサブネットに配置します。
D. Windows Server のフェールオーバー クラスタリングを使用して、SQL Server AlwaysOn の可用性グループを使用をセットアップします。 ノードを異なるゾーンに配置します。

D 正解
CloudSQLはMySQLとPostgreSQLしか対応してないからAはNG
スパナもDBエンジンを指定できんからNG
GCPではサブネットがゾーンを跨げるけど、サブネットを分けたからと言ってゾーンが分かれてるとは言えないからNG
いずれかのゾーンで～～って書いてることからしてもDがいい。

Reference:
– SQL Server AlwaysOn 可用性グループの構成
– SQL Server フェイルオーバー クラスタ インスタンスの構成
– Windows Server フェイルオーバー クラスタリングの実行


QUESTION 84 ★
オンプレミス環境からGoogle Cloud Storage にファイルをアップロードする必要があります。
お客様が提供する暗号鍵を使用して、Google Cloud Storage でファイルを暗号化する必要があります。
何をするべきでしょうか？

A. Boto 構成ファイルで暗号鍵を提供します。gsutilを使用してファイルをアップロードします。
B. gcloud config を使用して暗号鍵を提供します。gsutil を使用して、ファイルをそのバケットにアップロードします。
C. gsutil を使用してファイルをアップロードし、フラグ–encryption-key を使用して暗号鍵を指定します。
D. gsutil を使用してバケットを作成し、フラグ–encryption-key を使用して暗号鍵を指定します。gsutilを使用してファイルをそのバケットにアップロードします。

D → A
顧客指定の暗号鍵の使い方を知ってないと解けない。むずすぎる。
A.Boto構成ファイルで鍵暗号を指定して、gsutilでアップロード。正解。
B.CloudStorageで暗号鍵を使うのにgcloudコマンドは一切関係ないからNG。これは比較的簡単に外せる。
C,D.gsutilを使うっていうことにとらわれすぎてたけど、フラグ-encryption-keyなんてものは存在しないからおかしい。それだけの事。

顧客指定の暗号鍵：
    制限事項：
        顧客が独自のAES256で暗号化した鍵。
        CloudStorageTransferService,DataFlow,DataProcでは使えない。
        コンソール操作では使えない。
        個々のデータにのみ設定可能で、バケット単位で設定することはできない。
    利用方法：
        パートナー利用：Ionic Security や KeyNexus ってとこがやってくれるらしい
        JSON,XMLのAPI：
        gsutil：
            Boto構成ファイルの[GSUtil]セクションで encryption-key オプションを追加する。
            Boto構成ファイルに鍵指定すれば、gsutilのすべてのコマンドで適用される。

顧客管理の暗号鍵：CloudKMSを使って管理される鍵。

Reference:
– Boto を使用する場合
– 顧客指定の暗号鍵


QUESTION 88 ★
大規模なCRM 展開のデータベース バックエンドとしてGoogle Cloud SQL を使用しています。
使用量の増加に合わせて拡張し、ストレージが不足しないように、CPU 使用率コアを75 %に維持し、レプリケーションのラグを60 秒未満に抑える必要があります。
要件を満たすための正しい手順は何でしょうか？

A.
インスタンスの自動ストレージ増加を有効にします。
CPU 使用率が75 ％を超えた場合にStackdriver アラートを作成し、インスタンスタイプを変更してCPU 使用率を削減します。
レプリケーション ラグのStackdriver アラートを作成し、データベースを分割してレプリケーション時間を短縮します。
B.
インスタンスの自動ストレージ増加を有効にします。
インスタンスタイプを32コア マシンタイプに変更して、CPU 使用率を75 ％未満に保ちます。
レプリケーション ラグのStackdriver アラートを作成し、memcache を展開して、マスターの負荷を軽減します。
C.
ストレージが75 ％を超えたときにStackdriver アラートを作成し、インスタンスで使用可能なストレージを増やして、より多くのスペースを作成します。
memcached をデプロイして、CPU 負荷を減らします。
インスタンスタイプを32コア マシンタイプに変更して、レプリケーション ラグを減らします。
D.
ストレージが75 ％を超えたときにStackdriver アラートを作成し、インスタンスで使用可能なストレージを増やして、より多くのスペースを作成します。
memcached をデプロイして、CPU 負荷を減らします。
レプリケーション ラグのStackdriverアラートを作成し、インスタンスタイプを32コア マシンタイプに変更して、レプリケーション ラグを減らします。

A 正解
”使用量の増加に合わせて拡張”しないといけないから、32コアでマシンタイプを決めてるBはNG。
ストレージが75％かどうかはどうでもいいのでC,DはNG


QUESTION 91 ★
Google Kubernetes Engine クラスタで、CPU 負荷に基づいてノードを自動的に追加または削除する必要があります。
何をするべきでしょうか？

A. ターゲット CPU 使用率でHorizontalPodAutoscaler（HPA）を構成します。GCP Consoleからクラスタ オートスケーラーを有効にします。
B. ターゲット CPU 使用率でHorizontalPodAutoscaler（HPA）を構成します。gcloud コマンドを使用して、クラスターのマネージド インスタンス グループで自動スケーリングを有効にします。
C. デプロイメントを作成し、maxUnavailable およびmaxSurge プロパティを設定します。gcloud コマンドを使用して、クラスタ オートスケーラーを有効にします。
D. デプロイメントを作成し、maxUnavailable およびmaxSurge プロパティを設定します。 GCP Console からクラスタのマネージド インスタンス グループで自動スケーリングを有効にします。

B → A


QUESTION 92 ★
会社は全国的に運営されており、タイムクリティカルではないものを含む複数のバッチ ワークロードにGoogle Cloud Platafrom（GCP）を使用する予定です。
HIPAA 認定のGCP サービスを使用し、サービスコストを管理する必要もあります。
Google ベストプラクティスを満たすためにどのように設計する必要がありますか？

A. プリエンプティブル VMをプロビジョニングしてコストを削減し、HIPAA に準拠していないすべてのGCP サービスとAPI の使用を中止します。
B. プリエンプティブル VMをプロビジョニングして、コストを削減し、HIPAA に準拠していないすべてのGCP サービスとAPI の使用を無効にしてから使用を停止します。
C. コストを削減するために同じリージョンに標準 VMをプロビジョニングし、 HIPAA に準拠していないすべてのGCP サービスとAPI の使用を中止します。
D. 標準 VMを同じリージョンにプロビジョニングしてコストを削減し、HIPAA に準拠していないすべてのGCP サービスとAPI の使用を無効にしてから使用を停止します。

B 正解
タイムクリティカルじゃない・バッチジョブ実行　からプリエンプティブルVMで費用を削減できるのでA,B
HIPAAに準拠していないプロダクトを無効にしなかったら、使用してないことを確認してたとしても使用してしまうかもしれないし、AはNG

HIPAA：Health Insurance Portability and Accountability
    医療保険の相互運用性と説明責任に関する法律
GoogleのインフラストラクチャはHIPAAに準拠しているが、顧客のアプリケーションは顧客が確認する責任がある。
ベストプラクティス：BAA(Business Associate Agreement)を実行する。BAAに明示的に含まれていないGCPプロダクトを無効にするか、使用していないことを確認する。

Reference:
– Google Cloud Platform での HIPAA コンプライアンス
– HIPAA 対応プロジェクトの設定
– アーキテクチャ: HIPAA 対応の Cloud Healthcare


QUESTION 93 ★
顧客は、認証レイヤーの耐障害性テストを希望しています。
Google Cloud SQL インスタンスの読み取りと書き込みを行う公開 REST API を提供するリージョン マネージド インスタンス グループで構成されます。
何をするべきでしょうか？

A. セキュリティ企業と協力して、悪意のあるWebサイトからユーザの認証データを検索します。見つかった場合は通知するWebスクレイパーを実行します。
B. 不正アクセスを検出してログに記録するために、仮想マシンに侵入検知ソフトウェアを導入します。
C. ゾーン内のすべてのVMをシャットダウンしてアプリケーションの動作を確認できる災害シミュレーションの実行をスケジュールします。
D. マスターとは別のゾーンでGoogle Cloud SQL インスタンスの読み取りレプリカを設定し、REST API のKPI を監視しながら手動でフェイルオーバーをトリガーします。

D → C
耐障害性テストは、SQLインスタンスの冗長性じゃなくて、APIを提供するRegionMIGで提供される(VM)の話なのでDはNG
A,Bは耐障害性じゃなくて安全性のテストなのでNG
さすがに問題文がひどいと思います。


QUESTION 94 ★
マネージド インスタンス グループの作成を自動化したいと考えています。
VMには、多くのOS パッケージの依存関係があり、インスタンス グループ内の新しいVMの起動時間を最小限にしたいと望んでいます。
何をするべきでしょうか？

A. Terraform を使用して、マネージド インスタンス グループと起動スクリプトを作成し、OS パッケージの依存関係をインストールします。
B. すべてのOSパッケージの依存関係を持つカスタムVM イメージを作成します。 Google Cloud Deployment Manager を使用して、VM イメージでマネージド インスタンス グループを作成します。
C. Puppet を使用して、マネージドインスタンスグループを作成し、OSパッケージの依存関係をインストールします。
D. Google Cloud Deployment Manager を使用してマネージド インスタンス グループを作成し、Ansible でOS パッケージの依存関係をインストールします。

B 正解
”VMの起動時間を最小限にする”から、VM起動してから依存関係インストールするより、あらかじめインストールしておいたVMを起動するほうが早いからBが正解だと思います。


QUESTION 95 ★
アーキテクチャでは、プロジェクト内のすべての管理アクティビティとVM システムログを集中的に収集する必要があります。
これらのログをVMとサービスの両方からどのように収集する必要がありますか？

A.すべての管理およびVM システムログは、Stackdriver によって自動的に収集されます。
B. Stackdriver は、ほとんどのサービスの管理アクティビティログを自動的に収集します。システムログを収集するには、Stackdriver Logging エージェントを各インスタンスにインストールする必要があります。
C. カスタム syslogd VMを起動し、GCP プロジェクトとVMを設定して、すべてのログをそこに転送します。
D. Stackdriver Logging エージェントを単一のVMにインストールし、環境のすべての監査ログとアクセスログを収集します。

B 正解
システムログは自動で収集されない
監査ログ(Cloud Audit Log)は以下の3種類
    ・管理アクティビティログ：自動収集
    ・データアクセスログ：デフォルトでオフ
    ・システムイベントログ：自動収集


QUESTION 96 ★
Google App Engine アプリケーションを更新する必要があります。
現在のアプリケーションバージョンを置き換える前に、運用トラフィックで更新をテストします。
どうすれば良いでしょうか？

A. インスタンス グループ アップデータを使用して、部分ロールアウトを作成してカナリアテストを可能にします。
B. Google App Engine アプリケーションで更新を新しいバージョンとして展開し、トラフィックを新しいバージョンと現在のバージョンに分割します。
C. アップデートを新しいVPCにデプロイし、Google のグローバル HTTPロードバランシングを使用して、アップデートと現在のアプリケーション間でトラフィックを分割します。
D. 更新プログラムを新しいGoogle App Engineアプリケーションとして展開し、Googleのグローバル HTTP 負荷分散を使用して、新しいアプリケーションと現在のアプリケーションの間でトラフィックを分割します。

B 正解
他はどれも無駄が多い


QUESTION 97 ★
顧客は、eコマースサイトで使用されるWebサービスを実行して、製品の推奨事項をユーザーに提供します。
結果の品質を改善するために、Google Cloud Platform で機械学習モデルの実験を開始しました。
時間の経過とともにモデルの結果を改善するために、顧客は何をすべきでしょうか？

A. Google Cloud Machine Learning Engine のパフォーマンスメトリックをStackdriver からGoogle BigQuery にエクスポートし、モデルの効率性を分析します。
B. 機械学習モデルのトレーニングをGoogle Cloud GPU からGoogle Cloud TPU に移行するためのロードマップを作って、結果を改善します。
C. Google Compute Engine のアナウンスを監視して、新しいCPU アーキテクチャが利用できるかどうかを調べ、パフォーマンスを向上するようになったら、すぐにアーキテクチャにモデルをデプロイします。
D.推奨事項の履歴と推奨事項の結果をGoogle BigQuery に保存し、トレーニングデータとして使用します。

A → D
MachineLarningEngineのパフォーマンスを分析することは機械学習ではない。それは普通にパフォーマンスの分析やわ。なんで、AはNG。
TPU：Tensor Process Unit
GPUからTPUに移行するっていうのがよくわからんしBはNG？
Dが”時間の経過とともにモデルの結果を改善する”を実践できそう。


QUESTION 98 ★
会社の開発チームが、Docker化されたHTTPS Webアプリケーションを作成しました。
Google Kubernetes Engine（GKE）にアプリケーションをデプロイし、アプリケーションが自動的にスケーリングすることを確認する必要があります。
GKE は、どのようにデプロイするのが良いでしょうか？

A. 水平ポッド自動スケーリングを使用して、クラスタの自動スケーリングを有効にします。Ingress リソースを使用して、HTTPS トラフィックを負荷分散します。
B. 水平ポッド自動スケーリングを使用して、Kubernetes クラスタでクラスタの自動スケーリングを有効にします。LoadBalancer タイプのサービスリソースを使用してHTTPS トラフィックを負荷分散します。
C. Google Compute Engine インスタンス グループで自動スケーリングを有効にします。Ingress リソースを使用して、HTTPS トラフィックを負荷分散します。
D. Google Compute Engine インスタンス グループで自動スケーリングを有効にします。LoadBalancer タイプのサービスリソースを使用してHTTPS トラフィックを負荷分散します。

B 正解
Kubernetesの使い方。

Reference:
– クラスタの自動スケーリング


QUESTION 99 ★
会社は、ユーザが会社のWebサイトからダウンロードできるレンダリングソフトウェアを作成します。
会社には世界中に顧客がおり、すべてのお客様の遅延を最小限に抑える必要があります。
Google のベストプラクティスに従います。
ファイルはどのように保存しますか？

A. Google Cloud Multi-Regional Storageバケットにファイルを保存します。
B. Google Cloud Regional Storage バケットにファイルを保存します。リージョンのゾーンごとに1つのバケットがあります。
C. ファイルを複数のGoogle Cloud Regional Storage バケットに保存します。リージョンごとにゾーンごとに1つのバケットがあります。
D. ファイルを複数のGoogle Cloud Multi-Regional Storage バケットに保存します（Multi-Regionalごとに1つのバケット）。

D → A
