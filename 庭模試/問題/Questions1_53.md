1. この質問については、JencoMart のケーススタディを参照してください。
JencoMart のセキュリティチームは、すべてのGoogle Cloud Platform インフラストラクチャが運用リソースと開発リソースの分離した最小限の権限モデルを使ってデプロイされていることを望んでいます。
どのGoogle ドメインとプロジェクト構造をするべきでしょうか？

- [ ] ユーザーを管理するために開発/テスト/ステージング用と本番用の2つのG Suiteアカウントを作成します。各アカウントにはアプリケーションごとに1つのプロジェクトを含める必要があります。
- [ ] ユーザーを管理するために2つのG Suiteアカウントを作成します。1つはすべての開発アプリケーション用の単一プロジェクト、もう1つはすべての本番アプリケーション用の単一プロジェクトです。
- [ ] 1つのG Suiteアカウントを作成して、独自のプロジェクトの各アプリケーションの各段階でユーザーを管理します。
- [ ] 単一のG Suiteアカウントを作成して、開発/テスト/ステージング環境用の1つのプロジェクトと本番環境用の1つのプロジェクトでユーザーを管理します。


2. この質問については、JencoMart のケーススタディを参照してください。
JencoMart がユーザ認証情報データベースをGoogle Cloud Platform に移行して古いサーバをシャットダウンした数日後、新しいデータベースサーバはSSH 接続に応答しなくなりました。アプリケーション サーバーへのデータベース要求は正しく処理しています。
問題を診断するには、次のどの手順を実行する必要がありますか？（回答は3つ）

- [ ] 仮想マシン（VM）とディスクを削除して、新しいVMを作成します。
- [ ] インスタンスを削除し、ディスクを新しいVMに接続して調査します。
- [ ] ディスクのスナップショットを取得し、新しいマシンに接続して調査します。
- [ ] マシンが接続されているネットワークの受信ファイア ウォールルールを確認します。
- [ ] 非常に単純なファイアウォールルールを使用してVMを別のネットワークに接続し、調査します。
- [ ] トラブルシューティング用にインスタンスのシリアルコンソール出力を印刷し、インタラクティブコンソールをアクティブにして調査します。


3. この質問については、JencoMart のケーススタディを参照してください。JencoMartは、ユーザー プロファイル ストレージをGoogle Cloud Datastore に、アプリケーションサーバーをGoogle Compute Engine（GCE）に移行することを決定しました。
移行中に既存のインフラストラクチャはデータをアップロードするためにGoogle Cloud Datastore にアクセスする必要があります。
どのサービス アカウント キーの管理戦略を推奨する必要がありますか？

- [ ] オンプレミス インフラストラクチャとGCE 仮想マシン（VM）のサービス アカウント キーをプロビジョニングします。
- [ ] ユーザーアカウントを使用してオンプレミス インフラストラクチャを認証し、VMのサービス アカウント キーをプロビジョニングします。
- [ ] オンプレミス インフラストラクチャのサービス アカウント キーをプロビジョニングし、VMにGoogle Cloud Platform（GCP）管理鍵を使用します。
- [ ] GCE / Googleにカスタム認証サービスを展開します。 オンプレミスインフラストラクチャ用のGoogle Kubernetes Engine（GKE）およびVM用のGCP 管理キーを使用します。


4. この質問については、JencoMart のケーススタディを参照してください。JencoMartは、アジアへのトラフィックを提供するGoogle Cloud Platform 上にアプリケーションのバージョンを構築しました。
JencoMartのビジネスと技術的な目標に対する成功を測定したいと考えています。
どの指標を追跡する必要がありますか？

- [ ] アジアからのリクエストのエラー率。
- [ ] 米国とアジアの待ち時間の違い。
- [ ] アジアからの総訪問数、エラー率、および待ち時間。
- [ ] アジアのユーザーの合計訪問数と平均待ち時間。
- [ ] データベースに存在する文字セットの数。


5. この質問については、JencoMart のケーススタディを参照してください。
JencoMartのアプリケーションのGoogle Cloud Platform（GCP）への移行の進行が遅れています。インフラストラクチャを上図です。
スループットを最大化したいと望んでいます。
潜在的なボトルネックは何でしょうか？（回答は3つ）

- [ ] スループットを制限する単一のVPNトンネル。
- [ ] このタスクに適さないGoogle Cloud Storage の階層。
- [ ] 長距離での操作に適さないコピーコマンド。
- [ ] オンプレミス マシンよりもGCPの仮想マシン（VM）が少ない。
- [ ] VMの外部の独立したストレージレイヤー。このタスクには適していません。
- [ ] オンプレミス インフラストラクチャとGCP 間の複雑なインターネット接続。


6. この質問については、JencoMart のケーススタディを参照してください。JencoMartは、ユーザープロファイル データベースをGoogle Cloud Platformに移動したいと考えています。
どのGoogle データベースを使用する必要がありますか？

- [ ] Google Cloud Spanner
- [ ] Google BigQuery
- [ ] Google Cloud SQL
- [ ] Google Cloud Datastore


7. この質問については、Mountkirk Games のケーススタディを参照してください。
Mountkirk Gamesは、新しいテスト戦略を設計を望んでいます。
テストカバレッジは他のプラットフォームの既存バックエンドとどのように違うべきでしょうか ?

- [ ] テストは従来のアプローチをはるかに超えて拡張する必要があります。
- [ ] 単体テストは必要はなく、エンドツーエンドのテストだけが必要です。
- [ ] リリースが実稼働環境になった後にテストを適用する必要があります。
- [ ] テストにはGoogle Cloud Platform のインフラストラクチャのを直接テストを含める必要があります。


8. この質問については、Mountkirk Games のケーススタディを参照してください。
Mountkirk Gamesは、新しいバックエンドをGoogle Cloud Platform（GCP）にデプロイしました。
バックエンドの新しいバージョンが公開される前に、それらのバックエンドの完全なテストプロセスを作成し、テスト環境を経済的な方法で拡張する必要があります。
プロセスをどのように設計するべきでしょか？

- [ ] 本番環境の負荷をシミュレートするために、GCPでスケーラブルな環境を作成します。
- [ ] 既存のインフラストラクチャを使用して、GCP ベースのバックエンドを大規模にテストします。
- [ ] GCP内部のリソースを使用してアプリケーションの各コンポーネントにストレステストを構築し、負荷をシミュレートします。
- [ ] GCP で一連の静的環境を作成し、高/中/低 などのさまざまなレベルの負荷をテストします。


9. この質問については、Mountkirk Games のケーススタディを参照してください。
Mountkirk Gamesは、継続的デリバリーパイプラインの確率を望んでいます。
そのアーキテクチャには、迅速に更新およびロールバックできるように考えている小規模サービスが含まれています。
Mountkirk Gamesには次の要件があります。

サービスは、米国とヨーロッパの複数のリージョンに重複して導入されています。
フロントエンドサービスのみが公開インターネットで公開されます。
サービス群に単一のフロントエンド IPを提供できます。
デプロイメントの成果物は不変です。
どのプロダクトを使用するべきですか？

- [ ] Google Cloud Storage、Google Cloud Dataflow、Google Compute Engine.
- [ ] Google Cloud Storage、Google App Engine、Google Network Load Balancer.
- [ ] Google Kubernetes Registry、Google Container Engine、Google HTTP(S) Load Balancer.
- [ ] Google Cloud Functions、Google Cloud Pub/Sub、Google Cloud Deployment Manager.


10. この質問については、Mountkirk Games のケーススタディを参照してください。
Mountkirk Gamesのゲームサーバーは、自動的に適切にスケーリングされません。
先月、新機能を発表しから非常に人気になりました。記録的なユーザー数がサービスを使用しようとしていますが、多くは503 エラーと受け取り、応答時間が非常に遅くなっています。
最初に何を調査するべきでしょうか？

- [ ] データベースがオンラインであることを確認します。
- [ ] プロジェクトの割り当てを超えていないことを確認します。
- [ ] 新しい機能コードでパフォーマンスのバグが発生しなかったことを確認します。
- [ ] 負荷テストチームが本番環境に対してツールを実行していないことを確認します。

11. この質問については、Mountkirk Games のケーススタディを参照してください。
Mountkirk Gamesは、分離されたアプリケーション環境を展開するために、再現可能で構成可能なメカニズムを作成する必要があります。
開発者とテスターはお互いの環境とリソースにアクセスできますが、ステージングまたは本番環境のリソースにはアクセスできません。ステージング環境は、本番環境から一部のサービスにアクセスする必要があります。
開発環境をステージングおよび本番環境から分離するにはどうすればよいですか？

- [ ] 開発とテスト用のプロジェクトと、ステージングと本番用のプロジェクトを作成します。
- [ ] 開発とテスト用のネットワークと、ステージングと本番用のネットワークを作成します。
- [ ] 開発用に1つのサブネットワークを作成し、ステージングと本番用に別のサブネットワークを作成します。
- [ ] 開発用に1つ、ステージング用に2つ目、本番用に3つ目のプロジェクトを作成します。


12. この質問については、Mountkirk Games のケーススタディを参照してください。
Mountkirk Gamesは、新しいゲーム用にリアルタイムの分析プラットフォームをセットアップしたいと考えています。
新しいプラットフォームは、技術的要件を満たす必要があります。
すべての要件を満たすGoogle プロダクトの組み合わせはどれです？

- [ ] Google Kubernetes Engine、Google Cloud Pub/Sub、Google Cloud SQL.
- [ ] Google Cloud Dataflow、Google Cloud Storage、Google Cloud Pub/Sub、Google BigQuery.
- [ ] Google Cloud SQL、Google Cloud Storage、Google Cloud Pub/Sub、Google Cloud Dataflow.
- [ ] Google Cloud Dataproc、Google Cloud Pub/Sub、Google Cloud SQL、Google Cloud Dataflow.
- [ ] Google Cloud Pub/Sub、Google Compute Engine、Google Cloud Storage、Google Cloud Dataproc.


13.  ★この質問については、Mountkirk Games のケーススタディを参照してください。
Mountkirk Gamesは、現在の分析および統計レポートモデルから、Google Cloud Platform 上の技術的要件を満たすモデルに移行したいと考えています。
移行計画に含めるべき2つのステップはどれでしょうか？(回答は2つ)

- [ ] 現在のバッチ ETL コードをCloud Cloud Dataflow に移行した場合の影響を評価します。
- [ ] Google BigQuery のパフォーマンスを向上させるために、データを非正規化するスキーマ移行計画を作成します。
- [ ] 単一のMySQL データベースからMySQL クラスタに移動する方法を示すアーキテクチャ図を作成します。
- [ ] 前のゲームから10 TBの分析データをGoogle Cloud SQL インスタンスにロードし、データセット全体に対してテストクエリを実行して、正常に完了したことを確認します。
- [ ] Google Cloud Armor を統合して、Google Cloud Storage にアップロードされた分析ファイル内のSQL インジェクション攻撃の可能性を防ぎます。


14.  ★この質問については、Mountkirk Games のケーススタディを参照してください。
会社のMountkirk Gamesのコンピューティングワークロードの技術アーキテクチャを分析および定義する必要があります。
Mountkirk Gamesのビジネス要件と技術的要件を考慮して、何をすべきですか？

- [ ] ネットワーク ロードバランサを作成します。 Google Compute Engine プリエンプティブル インスタンスを使用します。
- [ ] ネットワーク ロードバランサを作成します。Google Compute Engine インスタンスを使用します。
- [ ] マネージド インスタンス グループ（MIG）と自動スケーリングポリシーを使用してネットワーク ロードバランサを作成します。Googel Compute Engine プリエンプティブル インスタンスを使用します。
- [ ] マネージド インスタンス グループ（MIG）と自動スケーリングポリシーを使用してネットワーク ロードバランサを作成します。 Google Compute Engine インスタンスを使用します。


15. この質問については、Mountkirk Games のケーススタディを参照してください。
Mountkirk Gamesは、パブリック クラウドと技術の改善が利用可能になったときにそれを活用するために、将来のためのソリューションを設計したいと考えています。
どのステップを取るべきですか？(回答は2つ)

- [ ] 将来のユーザー行動を予測するための機械学習モデルを訓練するために利用できるように、現在可能な限り多くの分析データとゲームアクティビティデータを保存します。
- [ ] ゲームバックエンド アーティファクトをコンテナイメージにパッケージ化し、Google Kubernetes Engine 上で実行することでゲームアクティビティに応じてスケールアップやスケールダウンできる可用性を改善します。
- [ ] Jenkins とSpinnaker を使って CI/CD パイプラインのセットアップを行い、カナリアの展開を自動化し、開発速度を改善します。
- [ ] 追加のプレーヤーデータをデータベースに保存する必要がある新しいゲーム機能を追加する際のダウンタイムを短縮するために、スキーマのバージョン管理ツールを採用します。
- [ ] Linux 仮想マシンに週単位のローリング メンテナンス プロセスを実装して、重要なカーネルパッチとパッケージアップデートを適用し、ゼロデイの脆弱性のリスクを軽減します。


16. この質問については、Mountkirk Games のケーススタディを参照してください。
Mountkirk Gamesは、モバイルネットワークの遅延の変化に対する分析プラットフォームの復元力をテストする方法を設計したいと考えています。
どうすればいいですか？

- [ ] ゲーム分析プラットフォームに障害注入ソフトウェアを導入し、モバイルクライアントの分析トラフィックに遅延を追加できます。
- [ ] Google Compute Engine 仮想マシンの携帯電話エミュレーターから実行できるテストクライアントを構築し、世界中のGoogle Cloud Platform リージョンで複数のコピーを実行して、現実的なトラフィックを生成します。
- [ ] モバイルデバイスからアップロードされた分析ファイルの処理を開始する前に、ランダムな遅延を導入する機能を追加します。
- [ ] プレーヤーのモバイルデバイスで実行し、世界中のGoogle Cloud Platform リージョンで実行されている分析エンドポイントから応答時間を収集するゲームのオプトインベータ版を作成します。


17. この質問については、Mountkirk Games のケーススタディを参照してください。
Mountkirk Games のデータベース ワークロードの技術アーキテクチャーを分析および定義する必要があります。
ビジネス要件と技術的要件を考慮してください。
どうすればいいですか？

- [ ] 時系列データにはGoogle Cloud SQL を使用し、履歴データクエリにはGoogle Cloud Bigtable を使用します。
- [ ] Google Cloud SQL を使用してMySQLを置き換え、Google Cloud Spanner を使用して履歴データクエリを実行します。
- [ ] Google Cloud Bigtable を使用してMySQLを置き換え、Google BigQuery を履歴データクエリに使用します。
- [ ] 時系列データにGoogle Cloud Bigtable を使用し、トランザクションデータにGoogle Cloud Spanner を使用し、履歴データクエリにGoogle BigQuery を使用します。


18.  ★この質問については、Mountkirk Games のケーススタディを参照してください。
時系列データベースサービスにゲームアクティビティを保存するためのMountkirk の技術的要件を満たすGoogle Cloud ストレージ プロダクトはどれでしょうか？

- [ ] Google Cloud Bigtable
- [ ] Google Cloud Spanner
- [ ] Google BigQuery
- [ ] Google Cloud Datastore


19.  ★この質問については、Mountkirk Games のケーススタディを参照してください。
新しいゲームバックエンド プラットフォームのアーキテクチャを担当しています。
ゲームはREST API を介してバックエンドと通信します。
Google のベストプラクティスに従います。
バックエンドをどのように設計すべきか？

- [ ] バックエンドのインスタンス テンプレートを作成します。 すべてのリージョンについて、複数ゾーンのマネージド インスタンス グループ（MIG）にデプロイします。 L4 ロードバランサ（TCP プロキシ負荷分散）を使用します。
- [ ] バックエンドのインスタンス テンプレートを作成します。 リージョンごとに、単一ゾーンのマネージド インスタンス グループ（MIG）にデプロイします。 L4 ロードバランサ（TCP プロキシ負荷分散）を使用します。
- [ ] バックエンドのインスタンス テンプレートを作成します。 すべてのリージョンについて、複数ゾーンのマネージド インスタンス グループ（MIG）にデプロイします。L7 ロードバランサ（HTTP(S) 負荷分散）を使用します。
- [ ] バックエンドのインスタンス テンプレートを作成します。 リージョンごとに、単一ゾーンのマネージド インスタンス グループ（MIG）にデプロイします。 L7 ロードバランサ（HTTP(S) 負荷分散）を使用します。


20. この質問については、TerramEarth のケーススタディを参照してください。
TerramEarthのCTOは、接続された車両の生データを使用して、現場の車がいつ壊滅的な故障を起こすかをおおよそ特定したいと考えています。
そのために、ビジネス アナリストが車両データを一元的に照会できるようにする必要があります。
どのアーキテクチャをおすすめしますか？

- [ ] a
- [ ] b
- [ ] c
- [ ] d


21. この質問については、TerramEarth のケーススタディを参照してください。
TerramEarthの開発チームは、ビジネス要件を満たすAPIを作成したいと考えています。
開発チームには、カスタム フレームワークを作成するのではなく、ビジネス バリューに開発作業を集中させる必要があります。
どの方法を良いでしょうか？

- [ ] Google App Engine をGoogle Cloud Endpoints で使用します。ディーラーおよびパートナー向けのAPIに注力します。
- [ ] JAX-RS Jersey Java ベースのフレームワークでGoogle App Engine を使用します。一般向けのAPIに注力します。
- [ ] Swagger（Open API 仕様）フレームワークでGoogle App Engineを使用します。一般向けのAPIに注力します。
- [ ] Django Python コンテナでGoogle Container Engine を使用します。 一般向けのAPIに注力します。
- [ ] Swagger（Open API 仕様）フレームワークを備えたTomcat コンテナでGoogle Container Engine を使用します。 ディーラーおよびパートナー向けのAPIに注力します。


22. この質問については、TerramEarth のケーススタディを参照してください。
開発チームは、車両データを取得するための構造化APIを作成しました。
開発チームは、この車両イベントデータを使用するディーラー用のツールをサードパーティが開発できるようにしたいと考えています。
このデータに対する委任された承認をサポートする必要があります。
どうすればいいでしょうか？

- [ ] OAuth と互換のあるアクセス制御システムを構築または活用します。
- [ ] SAML 2.0 SSO 互換性を認証システムに組み込みます。
- [ ] パートナーシステムのソース IP アドレスに基づいてデータアクセスを制限します。
- [ ] 信頼できるサードパーティに提供できる各ディーラーの二次認証情報を作成します。


23. この質問については、TerramEarth のケーススタディを参照してください。
TerramEarthは、現場にある2,000万台すべての車両をパブリック クラウドに接続することを計画しています。
これにより、2,000万600 バイトレコード/秒で40 TB/時のボリューム増加が予想されています。
データの取り込みをどのように設計する必要がありますか？

- [ ] 車両は、Google Cloud Storage にデータを直接書き込みます。
- [ ] 車両は、Google Cloud Pub/Sub にデータを直接書き込みます。。
- [ ] 車両は、データをGoogle BigQuery に直接ストリーミングします。
- [ ] 車両は、引き続き既存のシステム（FTP）を使用してデータを書き込みます。


24. この質問については、TerramEarth のケーススタディを参照してください。
TerramEarthのビジネス要件を分析したところ、ダウンタイムを削減し、顧客の部品の待ち時間を短縮することで、時間の大半を節約できることがわかりました。
3週間分の集約レポート時間の短縮に重点を置くことを決定しました。
会社のプロセスにどの変更するべきでしょうか？

- [ ] CSV形式からバイナリ形式に移行、FTPからSFTP トランスポートに移行を行い、メトリックの機械学習分析を開発します。
- [ ] FTPからストリーミング トランスポートへの移行、CSVからバイナリ形式への移行して、およびメトリックの機械学習分析を開発します。
- [ ] フリートのセルラー接続を80％に増やし、FTPからストリーミング トランスポートに移行し、メトリックの機械学習分析を開発します。
- [ ] FTPからSFTPトランスポートに移行し、メトリックの機械学習分析を開発し、ディーラーのローカル在庫を一定の要因で増やします。


25. この質問については、TerramEarth のケーススタディを参照してください。
Google Cloud Platform の利用を続ける結果、TerramEarthの設備投資（または資産計上）のどれが大きく変化するでしょうか？

- [ ] 運用コスト/設備投資の割り当て、LANの変更、容量計画。
- [ ] キャパシティプランニング、TCO計算、運用コスト/設備投資の割り当て。
- [ ] キャパシティプランニング、使用率測定、データセンターの拡張。
- [ ] データセンターの拡張、TCO計算、使用率測定。


26. この質問については、TerramEarth のケーススタディを参照してください。
データ取得を高速化するために、より多くの車両がセルラー接続にアップグレードされ、ETLプロセスにデータを送信できるようになります。
現在のFTP プロセスは頻繁にエラーを起こしやすく、接続に失敗するとファイルの初めからデータ転送を再開します。
ソリューションの信頼性を向上させ、セルラー接続でのデータ転送時間を最小限に抑える必要があります
どうすれば良いでしょうか？

- [ ] FTP サーバのGoogle Container Engine クラスタを1つ使用します。データを複数地域バケットに保存し、バケット内のデータを使用してETL プロセスの実行します。
- [ ] 異なる地域にあるFTP サーバを実行する複数のGoogle Container Engine クラスタを使用します。データを米国、EUおよびアジアの複数地域バケットに保存し、バケット内のデータを使用してETL プロセスを実行します。
- [ ] HTTP（S）上でGoogle API を使用して、米国、EU、アジア内のさまざまなGoogle Cloud Multi-Regional Storage バケット ロケーションにファイルを直接転送します。バケット内のデータを使用してETL プロセスを実行します。
- [ ] HTTP（S）上でGoogle API を使用して、米国、EU、アジア内の別のGoogle Cloud Regional Storage バケット ロケーションにファイルを直接転送します。ETL プロセスを実行して、各地域バケットからデータを取得します。


27. この質問については、TerramEarth のケーススタディを参照してください。
TerramEarthの2,000万台の車は世界中に散らばっています。
車両の位置に基づいて、テレメトリデータはGoogle Cloud Storage（GCS）のリージョンバケット（米国、欧州、アジア）に保存されています。
CTOは、なぜ車が100キロ走行した後に故障しているのかを判断するために、生のテレメトリデータに関するレポートの作成を望んでいます。
このジョブをすべてのデータに対して実行します。
このジョブを実行するための最も費用対効果の高い方法はどれでしょうか？

- [ ] すべてのデータを1つのゾーンに移動し、Google Cloud Dataproc クラスタを起動してジョブを実行します。
- [ ] すべてのデータを1つのリージョンに移動してから、Google Cloud Dataproc クラスタを起動してジョブを実行します。
- [ ] 各地域でクラスタを起動して未処理データを前処理および圧縮し、データを複数地域のバケットに移動し、Google Cloud Dataproc クラスタを使用してジョブを終了します。
- [ ] 各リージョンでクラスタを起動して生データを前処理および圧縮し、データをリージョンバケットに移動し、Google Cloud Dataproc クラスタを使用してジョブを仕上げます。


28. この質問については、TerramEarth のケーススタディを参照してください。
TerramEarthは、接続されているすべてのトラックにサーバとセンサーを搭載し、遠隔測定データを収集しています。
来年にこのデータを使用して機械学習モデルをトレーニングしたいと考えています。 またコストを削減しながら、このデータをパブリック クラウドに保存したいとも考えています。
何をすれば良いでしょうか？

- [ ] トラックのコンピューターに1時間ごとのスナップショットでデータを圧縮させ、Google Cloud Nearline Storage バケットに保存します。
- [ ] 遠隔測定データを、データを圧縮するストリーミングデータ フロージョブにリアルタイムでプッシュし、Google BigQuery に保存します。
- [ ] データを圧縮するストリーミングデータ フロージョブにリアルタイムで遠隔測定データをプッシュし、Google Cloud Bigtable に保存します。
- [ ] トラックのコンピューターに1時間ごとのスナップショットでデータを圧縮させ、Google Cloud Coldline Storage バケットに保存します。


29. この質問については、TerramEarth のケーススタディを参照してください。
農業部門は完全自動運転車の実験をしています。
車両の運用中に強力なセキュリティを強化するためのアーキテクチャが必要です。
どのアーキテクチャを検討する必要がありますか？(回答は2つ)

- [ ] 車両上のモジュール間のすべてのマイクロサービスコールを信頼できないものとして扱います。
- [ ] 安全なアドレス空間を確保するために、接続にIPv6 が必要です。
- [ ] トラステッドプラットフォームモジュール（TPM）を使用し、起動時にファームウェアとバイナリを確認します。
- [ ] 関数型プログラミング言語を使用して、コード実行サイクルを分離します。
- [ ] 冗長性のために複数の接続サブシステムを使用します。
- [ ] チップを分離するために、車両の駆動電子機器をファラデーケージに入れます。


30. この質問については、TerramEarth のケーススタディを参照してください。
TerramEarthの各車両は、環境条件に応じて油圧などの運転パラメータを調整して効率を向上させることができます。
主な目標は、携帯電話と未接続の2,000万台すべての車両の現場での作業効率を向上させることです。
この目標を達成するには何をすれば良いでしょうか？

- [ ] データのパターンを検査し、動作調整を自動的に行うルールを使用してアルゴリズムを作成します。
- [ ] すべての動作データをキャプチャし、理想的な動作を特定する機械学習モデルをトレーニングし、ローカルで実行して自動的に動作調整を行います。
- [ ] スライディング ウィンドウでGoogle Cloud Dataflow ストリーミング ジョブを実装し、Google Cloud Messaging（GCM）を使用して運用上の調整を自動的に行います。
- [ ] すべての操作データをキャプチャし、理想的な操作を識別する機械学習モデルをトレーニングし、Google Cloud Machine Learning（ML）プラットフォームでホストして、操作を自動的に調整します。


31. この質問については、TerramEarth のケーススタディを参照してください。
欧州連合の一般データ保護規則（GDPR）に準拠するために、TerramEarthは、個人データが含まれる36か月後にヨーロッパの顧客から生成されたデータを削除する必要があります。
新しいアーキテクチャでは、このデータはGoogle Cloud Storage とGoogle BigQuery の両方に保存されます。
何をするべきでしょうか？

- [ ] 欧州連合 データ用のGoogle BigQuery テーブルを作成し、テーブルの保存期間を36ヶ月に設定します。 Google Cloud Storageの場合、gsutil を使用して、36ヶ月のage 条件でDelete アクションを使用するライフサイクル管理を有効にします。
- [ ] 欧州連合 データ用のGoogle BigQuery テーブルを作成し、テーブルの保存期間を36ヶ月に設定します。Googel Cloud Storageの場合、36ヶ月のage 条件の場合、gsutil を使用してSetStorageClass to NONE アクションを作成します。
- [ ] 欧州連合 データ用のGoogle BigQuery タイムパーティション テーブルを作成し、パーティションの有効期限を36ヶ月に設定します。Google Cloud Storage の場合、gsutil を使用して、36ヶ月のage 条件でDelete アクションを使用するライフサイクル管理を有効にします。
- [ ] 欧州連合 データ用のGoogle BigQuery タイムパーティションテーブルを作成し、パーティション期間を36ヶ月に設定します。 Google Cloud Storageの場合、gsutilを使用して、36ヶ月のage 条件でSetStorageClass to NONE アクションを作成します。


32. この質問については、TerramEarth のケーススタディを参照してください。
TerramEarthは、データファイルをGoogle Cloud Storage（GCS）に保存することを決定しました。
GCS のライフサイクル ルールを設定して、1年間のデータを保存しますが、ファイルス トレージのコストを最小限に抑える必要があります。
どうすればいいでしょうか？

- [ ] 「 Age：30、Storage Class：Standard、アクション：Coldline に設定」でGCS のライフサイクル ルールを作成し、Age 条件で2つ目のGCS ライフサイクル ルールを作成します。
Age：365、Storage Class：Coldline、アクション：Delete
- [ ] 「 Age：30、Storage Class：Cloudline、アクション：Nearline に設定」でGCS のライフサイクル ルールを作成し、Age 条件で2つ目のGCS ライフサイクル ルールを作成します。
Age：91、Storage Class：Cloudline、アクション：Nearline に設定
- [ ] 「 Age：90、Storage Class：Standard、アクション：Nearline に設定」でGCS のライフサイクル ルールを作成し、Age 条件で2つ目のGCS ライフサイクル ルールを作成します。
Age：91、Storage Class：Nearline、アクション：Coldline に設定
D.「 Age：30、Storage Class：Standard、アクション：Coldline に設定」でGCS のライフサイクル ルールを作成し、Age 条件で2つ目のGCS ライフサイクル ルールを作成します。
Age：365、Storage Class：Nearline、アクション：Delete


33.  ★この質問については、TerramEarth のケーススタディを参照してください。
TerramEarthのデータ ウェアハウスに、信頼性と拡張性に優れたGCP ソリューションを実装する必要があります。
TerramEarthのビジネス要件と技術的要件を考慮してください。
何をするべきでしょうか？

- [ ] 既存のデータ ウェアハウスをGoogle BigQueryに置き換え、パーティション分割テーブルを使用します。
- [ ] 既存のデータ ウェアハウスを96個のvCPUを持つGoogle Compute Engine インスタンスに置き換えます。
- [ ] 既存のデータ ウェアハウスをGoogle BigQuery に置き換え、外部データソース（フェデレーション データソース）を使用します。
- [ ] 既存のデータ ウェアハウスを96個のvCPUのGoogle Compute Engine インスタンスに置き換え、 32個のvCPUのGoogle Compute Engine プリエンプティブル インスタンスを追加します。


34.  ★この質問については、TerramEarth のケーススタディを参照してください。
すべての入力データをGoogle BigQuery に書き込む新しいアーキテクチャが導入されました。
データが汚れていることに気付き、コストを管理しながら、毎日自動化されたデータ品質を確保したいと考えています。
何をするべきでしょうか？

- [ ] Google Cloud Dataflow ストリーミング ジョブを設定し、取り込みプロセスでデータを受信します。 Google Cloud Dataflow パイプラインのデータをクリーンアップします。
- [ ] Google BigQuery からデータを読み取り、クリーンアップするGoogle Cloud Functions を作成します。Google Compute EngineインスタンスからGoogle Cloud Functions をトリガーします。
- [ ] Google BigQuery のデータにSQL文を作成し、ビューとして保存します。 ビューを毎日実行し、結果を新しいテーブルに保存します。
- [ ] Google Cloud Dataprep を使用して、Google BigQuery テーブルをソースとして構成します。 データを消去するために毎日のジョブをスケジュールします。


35.  ★この質問については、TerramEarth のケーススタディを参照してください。
TerramEarthの技術的要件を考慮した場合、Google Cloud Platform で予想外の車両のダウンタイムをどのように削減するべきですか?

- [ ] Google BigQuery をデータ ウェアハウスとして使用します。 すべての車両をネットワークに接続し、Google Cloud Pub/Sub とGoogle Cloud Dataflow を使用してデータをGoogle BigQuery にストリーミングします。分析とレポートにGoogle データポータル（データスタジオ） を使用します。
- [ ] Google BigQuery をデータ ウェアハウスとして使用します。すべての車両をネットワークに接続し、gcloud を使用してgzip ファイルをGoogle Cloud Multi-Regional Storage バケットにアップロードします。 分析とレポートにGoogle データポータルを使用します。
- [ ] Google Cloud Dataproc Hive をデータ ウェアハウスとして使用します。gzip ファイルをGoogle Cloud Multi-Regional Storage バケットにアップロードします。gcloud を使用して、このデータをGoogle BigQuery にアップロードします。分析とレポートにGoogle データポータルを使用します。
- [ ] Google Cloud Dataproc Hive をデータウェアハウスとして使用します。パーティション化されたHive テーブルにデータを直接ストリーミングします。Pig スクリプトを使用してデータを分析します。


36.  ★この質問については、TerramEarth のケーススタディを参照してください。
携帯電話ネットワークに接続されている20万台の車両のデータを取り込むための新しいアーキテクチャを設計するよう求められます。
Google のベストプラクティスに従ってください。
TerramEarthの技術的要件を考慮すると、データの取り込みにはどのコンポーネントを使用する必要がありますか。

- [ ] SSL Ingress を使用したGoogle Kubernetes Engine。
- [ ] 公開鍵 / 秘密鍵ペアを使用したGoogle Cloud IoT Core。
- [ ] プロジェクト全体のSSH 認証鍵を備えたGoogle Compute Engine。
- [ ] 特定のSSH 認証鍵を持つGoogle Compute Engine。


37. この質問については、Dress4Win のケーススタディを参照してください。
Dress4Winのセキュリティチームは、Google Cloud Platform（GCP）上の運用仮想マシン（VM）への外部 SSH アクセスを無効しました。
運用チームはVMをリモートで管理し、Docker コンテナのビルドとプッシュし、Google Cloud Storage オブジェクトの管理を行う必要があります。
セキュリティチームは、運用チームに何をするべきでしょうか？

- [ ] 運用エンジニアにGoogle Cloud Shell へのアクセス権を付与します。
- [ ] GCP へのVPN 接続を構成し、GCP のVMへのSSH アクセスを許可します。
- [ ] 運用エンジニアがタスクを実行する必要がある場合に、GCP のVMへの一時的なSSH アクセスを許可する新しいアクセス要求プロセスを開発します。
- [ ] 開発チームにAPI サービスを構築して、運用チームが特定のリモート プロシージャ コール（RPC）を実行してタスクを実行できるようにします。


38.  ★この質問については、Dress4Win のケーススタディを参照してください。Dress4Winでは、運用エンジニアが、データベースのバックアップ ファイルのコピーをリモートでアーカイブするための低コストのソリューションを作成しようとしています。
データベース ファイルは、現在のデータセンターに格納されている圧縮 tar ファイルです。
何をするべきでしょうか？

- [ ] gsutil を使用してcron スクリプトを作成し、ファイルをColdline Storage バケットにコピーします。
- [ ] gsutil を使用してcron スクリプトを作成し、ファイルをRegional Storage バケットにコピーします。
- [ ] Google Cloud Storage Transfer Service ジョブを作成して、ファイルをColdline Storage バケットにコピーします。
- [ ] Google Cloud Storage Transfer Service ジョブを作成して、ファイルをRegional Storage バケットにコピーします。


39. この質問については、Dress4Win のケーススタディを参照してください。Dress4Winは、アプリケーション サーバで使用するマシンタイプの導入を検討しています。
何をするべきでしょうか？

- [ ] オンプレミスの物理ハードウェア コアとRAMをパブリック クラウド内の最も近いマシンタイプにマッピングします。
- [ ] Dress4Winには、CPUに対するRAMの比率が最も高いマシンタイプにアプリケーション サーバを導入することをお勧めします。
- [ ] Dress4Winには、最小のインスタンスを使用して本番環境に導入し、時間をかけて監視し、目的のパフォーマンスに達するまでマシンタイプをスケールアップすることをお勧めします。
- [ ] アプリケーション サーバの仮想マシンに関連付けられた仮想コアとRAMの数を特定し、パブリック クラウド内のカスタム マシンタイプに合わせてパフォーマンスを監視し、目的のパフォーマンスに達するまでマシンタイプをスケールアップします。


40. この質問については、Dress4Win のケーススタディを参照してください。
Dress4Winのパブリック クラウドへの移行計画の一環として、トラフィック負荷の急増に対処できるようにロギングとモニタリングの管理システムをセットアップしたいと考えています。
Dress4Winが希望する保証項目：

インフラストラクチャは、1日の使用量の増減を処理するためにスケールアップおよびスケールダウンが必要になったときの通知。
アプリケーションがエラー報告したときの管理者に自動通知。
集約されたログをフィルタリングして、多くのホストでアプリケーションの一部をデバッグ。
Google StackDriver のどの機能を使うべきか?

- [ ] Logging、Alerts、Insights、Debug。
- [ ] Monitoring, Trace, Debug, Logging。
- [ ] Monitoring, Logging, Alerts, Error Reporting。
- [ ] Monitoring, Logging, Debug, Error Report。


41. この質問については、Dress4Win のケーススタディを参照してください。
Dress4Winは、一部のアプリケーションをそのまま迅速に正常にデプロイすることにより、パブリック クラウドへのアプリケーションのデプロイに精通したいと考えています。
何を行えばよいでしょうか？

- [ ] パブリック クラウドへの最初の移行として、外部に依存する自己完結型アプリケーションを特定します。
- [ ] 内部的に依存しているエンタープライズアプリケーションを特定し、パブリック クラウドへの最初の移行します。
- [ ] 社内データベースをパブリック クラウドに移行し、オンプレミス アプリケーションへのリクエストを継続的に処理します。
- [ ] メッセージ キュー サーバをパブリック クラウドに移動し、オンプレミス アプリケーションへのリクエストの処理を続行します。


42. この質問については、Dress4Win のケーススタディを参照してください。
Dress4Winは、オンプレミスのMySQL 環境をパブリック クラウドに移行する方法についてアドバイスを求めています。
移行中の自社運用ソリューションへのダウンタイムとパフォーマンスの影響を最小限に抑えたいと考えています。
何をすれば良いでしょうか？

- [ ] オンプレミス MySQL マスターサーバのダンプ（dump）ファイルを作成し、シャットダウンしてパブリック クラウド環境にアップロードし、新しいMySQL クラスタにロードします。
- [ ] パブリック クラウド環境でMySQL レプリカサーバ/スレーブを設定し、カットオーバまでオンプレミスのMySQL マスターサーバから非同期レプリケーション用に構成します。
- [ ] パブリック クラウドに新しいMySQL クラスタを作成し、オンプレミスとパブリック クラウドの両方のMySQL マスターへの書き込みを開始するようにアプリケーションを構成し、カットオーバー時に元のクラスタを破棄します。
- [ ] MySQL レプリカサーバのダンプ ファイルをパブリック クラウド環境に作成してGoogle Cloud Datastore にロードし、カットオーバ時にGoogle Cloud Datastore に対して読み取り/書き込みを行うようにアプリケーションを構成します。


43. この質問については、Dress4Win のケーススタディを参照してください。
Dress4Winは、従来のサービスのいくつかについて、Google Stackdriver で新しい稼働時間チェックを設定しました。
Stackdriver ダッシュボードは、サービスが正常であると報告していません。
何をするべきでしょうか？

- [ ] すべての従来のWebサーバにStackdriver エージェントをインストールします。
- [ ] Google Cloud Platform Console で、アップタイムサーバのIP アドレスのリストをダウンロードし、インバウンド ファイアウォール ルールを作成します。
- [ ] 値がGoogleStackdriverMonitoring-UptimeChecks と一致したときにUser-Agent HTTP ヘッダーを通過するようにロードバランサーを構成します。（https://cloud.google.com/monitoring）
- [ ] 値がGoogleStackdriverMonitoringUptimeChecks と一致する場合、user-Agent HTTPヘッダーを含むリクエストを許可するように従来のWebサーバーを設定します。(https://cloud.google.com/monitoring)


44. この質問については、Dress4Win のケーススタディを参照してください。
新しいアプリケーション体験の一環として、Dress4Wmでは顧客が自分の画像をアップロードできます。
顧客は、これらのイメージを表示できるユーザーを独占的に管理できます。
顧客は、最小限の待ち時間で画像をアップロードでき、ログイン時にメイン アプリケーション ページに画像をすばやく表示できる必要があります。
どの構成を使用するべきでしょうか？

- [ ] Google Cloud Storage バケットに画像ファイルを保存します。Google Cloud Datastore を使用して、各顧客のIDとその画像ファイルをマッピングするメタデータを維持します。
- [ ] Google Cloud Storage バケットに画像ファイルを保存します。顧客の一意のIDを含むGoogle Cloud Storageのアップロードされた画像にカスタムメタデータを追加します。
- [ ] 分散ファイルシステムを使用して、顧客の画像を保存します。ストレージのニーズが増えたときには、永続ディスクやノードを追加します。各ファイルの所有者属性を設定する一意のIDを各顧客に割り当て、画像のプライバシーを確保します。
- [ ] 分散ファイルシステムを使用して、顧客の画像を保存します。ストレージのニーズが増えたときには、永続ディスクやノードを追加します。Google Cloud SQL データベースを使用して、各顧客のIDを画像ファイルにマッピングするメタデータを維持します。


45. この質問については、Dress4Win のケーススタディを参照してください。
Dress4Winには、エンドポイントの100％をカバーするエンドツーエンドのテストがあります。
パブリック クラウドへの移行によって新しいバグが発生しないようにしたいと考えています。
停止を防ぐために開発者はどのような追加のテスト方法を採用するべきですか？

- [ ] アプリケーション コードでGoogle Stackdriver Debugger を有効にして、コード内のエラーを表示する必要があります。
- [ ] パブリック クラウドのステージング環境にユニット（単体）テストと実稼働規模の負荷テストを追加する必要があります。
- [ ] パブリック クラウドのステージング環境でエンドツーエンドのテストを実行して、コードが意図したとおりに機能しているかどうかを判断する必要があります。
- [ ] カナリアテストを追加して、開発者が新しいリリースが遅延に与える影響を測定できるようにします。


46. この質問については、Dress4Win のケーススタディを参照してください。
Dress4Winの販売記録と税記録は、監査人が少なくとも10年間は見ることはありません。
最優先事項は、コストの最適化です。
どのGoogle プロダクトを選択するべきでしょうか？

- [ ] データはGoogle Cloud Coldline Storage に保存し、gsutil でデータにアクセスします。
- [ ] データはGoogle Cloud Nearline Storage に保存し、gsutil でデータにアクセスします。
- [ ] データはアメリカまたはヨーロッパ リージョンを指定し、Google Bigtabte に保存し、gcloud でデータにアクセスします。
- [ ] データはGoogle BigQuery に保存し、マネージド インスタンス グループ（MIG）内のWebサーバ クラスタでデータにアクセスします。Google Cloud SQL に、データを格納するために2つの異なるリージョンにミラーリングを行い、マネージド インスタンス グループ（MIG）内のRedis クラスタにミラーリングされたデータにアクセスします。


47. この質問については、Dress4Win のケーススタディを参照してください。
現在のDress4winのシステム アーキテクチャは、1つのデータセンターに配置されているため、一部のお客様によってはレーテンシーが高くなることがあります。
パブリック クラウドでのパフォーマンスの将来の評価と最適化の時点で、Dresses4winは、Google Cloud Platform のシステムアーキテクチャを複数の場所に配布したいと考えています。
どのアプローチを採用するべきですか？

- [ ] リージョン マネージド インスタンス グループとグローバル負荷分散を使用してパフォーマンスを向上させます。リージョン マネージド インスタンス グループは、トラフィックに基づいて各地域のインスタンスを個別に拡大できるためです。
- [ ] 運用チームが管理する仮想マシンのより近いグループにリクエストを転送する仮想マシンのセットでグローバル負荷分散を使用します。
- [ ] リージョン マネージド インスタンス グループとグローバル負荷分散を使用して、異なるリージョンのゾーン間で自動フェールオーバーを提供することにより、信頼性を向上させます。
- [ ] 個別のマネージド インスタンス グループの一部として、リクエストをより近い仮想マシンのグループに転送する一連の仮想マシンでグローバル負荷分散を使用します。


48. この質問については、Dress4Win のケーススタディを参照してください。
Dress4Winは、既存の使用パターンを反映したデータとトラフィックの対応する成長とともに、1年でそのサイズの10倍に成長すると予想されます。
CIOは、今後6ヵ月以内に運用しているインフラストラクチャをパブリック クラウドに移行するという目標を設定しました。
アプリケーションに大きな変更することなく、この成長に合わせて拡張し、ROI を最大化するようにソリューションをどのように構成すれば良いでしょうか？

- [ ] Web アプリケーション レイヤーをGoogle App Engine に、MySQL をGoogle Cloud Datastore に、NASをGoogle Cloud Storage に移行します。RabbitMQ をデプロイし、Google Cloud Deployment Manager を使ってHadoop サーバをデプロイします。
- [ ] RabbitMQ をGoogle Cloud Pub/Subに、Hadoop をGoogle BigQueryに、NASをGoogle Compute Engine とPersistent Disk ストレージに移行します。Tomcat をデプロイして、Google Cloud Deployment Manager を使ってNginx をデプロイします。
- [ ] Tomcat およびNginx 用のマネージド インスタンス グループを実装します。MySQL をGoogle Cloud SQL に、RabbitMQ をGoogle Cloud Pub/Sub に、Hadoop をGoogle Cloud Dataproc に、NAS をGoogle Compute Engine とPersistent Disk ストレージに移行します。
- [ ] Tomcat およびNginx 用のマネージド インスタンス グループを実装します。MySQL をGoogle Cloud SQL に、RabbitMQ をGoogle Cloud Pub/Sub に、Hadoop をGoogle Cloud Dataproc に、NASをGoogle Cloud Storage に移行します。


49. この質問については、Dress4Win のケーススタディを参照してください。
特定のビジネス要件を考慮して、Webおよびトランザクション データレイヤーの導入をどのように自動化すれば良いでしょうか？

- [ ] Google Cloud Deployment Manager を使用して、Nginx とTomcat をGoogle Compute Engine にデプロイします。 MySQL を置き換えるCloud SQL サーバをデプロイします。Google Cloud Deployment Manager を使用してJenkins を展開します。
- [ ] Google Cloud Platform（GCP）Marketplace を使用してNginx とTomcat を展開します。GCP Marketplace を使用してMySQL サーバを展開します。Google Cloud Deployment Manager スクリプトを使用して、Jenkins をGoogle Compute Engine にデプロイします。
- [ ] Nginx とTomcat をGoogle App Engine に移行します。Google Cloud Datastore サーバをデプロイして、高可用性構成のMySQL サーバを置き換えます。GCP Marketplace を使用してJenkins をGoogle Compute Engine にデプロイします。
- [ ] Nginx とTomcat をGoogle App Engine に移行します。GCP Marketplace を使用してMySQL サーバを展開します。GCP Marketplace を使用してJenkins をGoogle Compute Engine にデプロイします。


50. この質問については、Dress4Win のケーススタディを参照してください。
どのコンピューティングサービスをそのまま移行を行うと、パブリック クラウドでのパフォーマンスのために最適化されたアーキテクチャになりますか？

- [ ] Google App Engine スタンダード環境を使用して展開されたWebアプリケーション。
- [ ] 管理されていないインスタンス グループを使用して展開されたRabbitMQ。
- [ ] 高可用性モードでGoogle Cloud Dataproc Regional を使用して展開されたHadoop/Spark。
- [ ] ジェンキンス、監視、要塞ホスト、カスタムマシンタイプに展開されたセキュリティスキャナーサービス。


51. この質問については、Dress4Win のケーススタディを参照してください。
監査中に法令に準拠するためには、Dress4WinはGoogle Cloud 上のリソース構成やメタデータを変更するすべての管理アクションを洞察できなければなりません。
何をするべきでしょうか？

- [ ] Stackdriver Trace を使用して、トレースリスト分析を作成します。
- [ ] Stackdriver Monitoring を使用して、プロジェクトのアクティビティに関するダッシュボードを作成します。
- [ ] すべてのプロジェクトでCloud Identity-Aware Proxy を有効にし、管理者（Administrators）グループをメンバーとして追加します。
- [ ] Google Cloud Platform Console のアクティビティページとStackdriver Logging を使用して、必要な洞察を提供します。


52.  ★この質問については、Dress4Win のケーススタディを参照してください。Dress4WinのGoogle Cloud Storage に保存されたデータのセキュリティに責任があります。
既にGoogle グループのセットを作成し、適切なユーザーをそれらのグループに割り当てています。
Google ベストプラクティスに従って、ビジネス要件と技術的要件を満たすために最も単純な設計を実装する必要があります。
何をするべきでしょうか？

- [ ] セキュリティ要件を実施するために、作成したGoogl eグループにIAMのカスタムの役割を割り当てます。Google Cloud Storage にファイルを保存するときに、顧客が用意した暗号鍵でデータを暗号化します。
- [ ] セキュリティ要件を実施するために、作成したGoogle グループにIAMのカスタムの役割を割り当てます。Google Cloud Storage にファイルを保存する前に、デフォルトのストレージ暗号化を有効します。
- [ ] セキュリティ要件を実施するために、作成したGoogle グループに定義済みのIAMの役割を割り当てます。Google Cloud Storage にファイルを保存するときに、Google のデフォルトの暗号化を保存時に使用します。
- [ ] セキュリティ要件を実施するために、作成したGoogle グループに定義済みのIAM の役割を割り当てます。Google Cloud Storage にファイルを保存する前に、デフォルトのGoogle Cloud KMS の暗号鍵が設定されていることを確認します。


53.  ★この質問については、Dress4Win のケーススタディを参照してください。
ソリューションを移行する前に、オンプレミス アーキテクチャがビジネス要件を満たしていることを確認する必要があります。
オンプレミスのアーキテクチャをどのように変更する必要がありますか？

- [ ] RabbitMQ をGoogle Cloud Pub / Subに置き換えます。
- [ ] MySQL をGoogle Cloud SQL for MySQL でサポートされているv5.7にダウングレードします。
- [ ] 事前定義されたGoogle Compute Engine マシンタイプに一致するようにコンピューティング リソースのサイズを変更します。
- [ ] マイクロサービスをコンテナ化し、Google Kubernetes Engine でホストします。